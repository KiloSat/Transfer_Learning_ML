{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransLearnRN-18",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJN6pyKBf4Nt"
      },
      "source": [
        "We will use pretrained models for classifying Ants and Bees. This is called as transfer learning.<br>\n",
        "Why? Because while solving real world problems, almost no one trains the entire cnn models by themselves. \n",
        "\n",
        "These two major transfer learning scenarios look as follows:<br>\n",
        "(1) Finetuning the convnet: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\n",
        "\n",
        "(2) ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv_Peij9iWdX"
      },
      "source": [
        "**Scenario 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJVgClSSJ13y"
      },
      "source": [
        "# A library is a collection of packages\n",
        "# packages are collection of modules, which together provide some functionality.\n",
        "# modules contain classes and functions.\n",
        "# scripts contain functions and modules which are run to provide some output.\n",
        "\n",
        "from __future__ import print_function, division \n",
        "\n",
        "import torch                                                                    # importing pytorch package\n",
        "import torch.nn as nn                                                           # importing neural networks package\n",
        "import torch.optim as optim                                                     # importing optimizer package\n",
        "from torch.optim import lr_scheduler                                            # importing learning rate module \n",
        "import numpy as np                                                              # importing numpy library \n",
        "import torchvision                                                              # importing torchvision package\n",
        "from torchvision import datasets, models, transforms                            # importing models,datasets and transform packages\n",
        "import matplotlib.pyplot as plt                                                 # importing matplotlib.pyplot module\n",
        "import time                                                                     # importing time module     \n",
        "import os                                                                       # importing os module   \n",
        "import copy                                                                     # importing copy module\n",
        "\n",
        "plt.ion()                                                                       # turns on interactive mode in matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Zz8qYre9c3"
      },
      "source": [
        "Download the dataset from [here](https://download.pytorch.org/tutorial/hymenoptera_data.zip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sEHz_08KM25"
      },
      "source": [
        "!unzip \"hymenoptera_data.zip\"  -d \"hymenoptera_data\"                            # extracting the contents of the uploaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UzzkFT2RNxc",
        "outputId": "1a9c6167-d383-4cce-8f6b-761b095d5603"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'hymenoptera_data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8hKEOG7l_bN",
        "outputId": "d8131d5f-d012-4146-abf0-10fbbbdae643"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w43yZx7mOwv"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVBY_0gmbHV"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypH3YZKxmemF"
      },
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14KwH0v9mhUe",
        "outputId": "9ea3e511-e443-44d9-b24e-2bb50b4191f9"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5981 Acc: 0.6762\n",
            "val Loss: 0.2282 Acc: 0.9020\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.3663 Acc: 0.8402\n",
            "val Loss: 0.2435 Acc: 0.9085\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6038 Acc: 0.7992\n",
            "val Loss: 0.4565 Acc: 0.8627\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.5727 Acc: 0.7787\n",
            "val Loss: 0.2516 Acc: 0.8562\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.4763 Acc: 0.7992\n",
            "val Loss: 0.2407 Acc: 0.9020\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.4616 Acc: 0.8279\n",
            "val Loss: 0.3873 Acc: 0.8431\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.4633 Acc: 0.8074\n",
            "val Loss: 0.3435 Acc: 0.8497\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4319 Acc: 0.8279\n",
            "val Loss: 0.2245 Acc: 0.8758\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "val Loss: 0.2088 Acc: 0.9281\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.2729 Acc: 0.8893\n",
            "val Loss: 0.1909 Acc: 0.9412\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.2663 Acc: 0.8975\n",
            "val Loss: 0.2126 Acc: 0.9281\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.3439 Acc: 0.8443\n",
            "val Loss: 0.2024 Acc: 0.9281\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2550 Acc: 0.8975\n",
            "val Loss: 0.1849 Acc: 0.9346\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.3628 Acc: 0.8484\n",
            "val Loss: 0.1818 Acc: 0.9281\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2513 Acc: 0.8852\n",
            "val Loss: 0.1710 Acc: 0.9346\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.3207 Acc: 0.8689\n",
            "val Loss: 0.1873 Acc: 0.9281\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.3017 Acc: 0.8689\n",
            "val Loss: 0.2084 Acc: 0.9150\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2929 Acc: 0.8893\n",
            "val Loss: 0.1838 Acc: 0.9216\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.3188 Acc: 0.8402\n",
            "val Loss: 0.1687 Acc: 0.9477\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2295 Acc: 0.8934\n",
            "val Loss: 0.1641 Acc: 0.9477\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2711 Acc: 0.8852\n",
            "val Loss: 0.1756 Acc: 0.9477\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.4196 Acc: 0.8074\n",
            "val Loss: 0.1734 Acc: 0.9216\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.3234 Acc: 0.8361\n",
            "val Loss: 0.1760 Acc: 0.9412\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.2822 Acc: 0.9016\n",
            "val Loss: 0.1857 Acc: 0.9020\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.2273 Acc: 0.8852\n",
            "val Loss: 0.1692 Acc: 0.9477\n",
            "\n",
            "Training complete in 34m 7s\n",
            "Best val Acc: 0.947712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g4MuzLJmi0M",
        "outputId": "81de6cdf-5e12-4b79-d34a-e3baffee0298"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UilTcvAu9Ru6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}